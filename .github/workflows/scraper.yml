name: Scraper

on:
  schedule:
    - cron: '30 14 * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    name: Run Scraper
    runs-on: ubuntu-24.04-arm
    environment: Scraper

    env:
      DEFAULT_LOGGING_LEVEL: ${{ secrets.DEFAULT_LOGGING_LEVEL }}
      YEAR: ${{ secrets.YEAR }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create .env file
        run: |
          echo "DEFAULT_LOGGING_LEVEL=${{ env.DEFAULT_LOGGING_LEVEL }}" > src/.env
          echo "YEAR=${{ env.YEAR }}" >> src/.env

      - name: Build Docker image
        run: docker build -f scraper.Dockerfile -t courses-api-scraper:latest .

      - name: Install Turso CLI
        run: |
          curl -sSfL https://get.tur.so/install.sh | bash
          echo "$HOME/.turso/bin" >> $GITHUB_PATH

      - name: Login to Turso CLI
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
        run: turso login --api-token "$TURSO_API_TOKEN" --headless

      - name: Run scraper
        run: |
          docker run --rm \
          -v ${{ github.workspace }}/src:/app/src \
          -e DEFAULT_LOGGING_LEVEL=${{ env.DEFAULT_LOGGING_LEVEL }} \
          -e YEAR=${{ env.YEAR }} \
          courses-api-scraper:latest

      - name: Import SQLite DB to Turso
        run: turso db import --db courses-api src/dev.sqlite3
