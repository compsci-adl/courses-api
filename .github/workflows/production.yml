name: Production
permissions:
  contents: read

on:
  push:
    branches: [main]

env:
  AWS_REGION: ap-southeast-2

jobs:
  lint-format:
    name: Linting Checks
    uses: ./.github/workflows/lint.yml

  build:
    needs: lint-format
    name: Build
    runs-on: ubuntu-24.04-arm
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@b547701ef94ff7a3c3d8ea1eead705e6ceaf3871 # v5
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: ${{ secrets.AWS_ROLE_SESSION_NAME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

      - name: Cache Docker layers
        uses: actions/cache@9255dc7a253b0ccc959486e2bca901246202afeb # v5
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Build Docker container
        env:
          PRODUCTION_BUILD: 'true'
        run: |
          docker buildx build \
            --cache-from=type=local,src=/tmp/.buildx-cache \
            --cache-to=type=local,dest=/tmp/.buildx-cache-new,mode=max \
            --output type=docker,dest=courses-api.tar \
            --platform=linux/arm64 --file=Dockerfile -t courses-api .
          gzip courses-api.tar

      - name: Save Docker cache
        if: success()
        run: |
          rsync -a --delete /tmp/.buildx-cache-new/ /tmp/.buildx-cache/

      - name: Copy image and compose file to S3
        run: |
          aws s3 cp ./courses-api.tar.gz s3://${{ secrets.AWS_S3_BUCKET }}/courses-api/
          aws s3 cp ./docker-compose.yml s3://${{ secrets.AWS_S3_BUCKET }}/courses-api/

  deploy:
    needs: build
    name: Deploy
    runs-on: ubuntu-latest
    environment: Production
    steps:
      - name: Deploy on EC2
        env:
          KEY: ${{ secrets.SSH_EC2_KEY }}
          HOSTNAME: ${{ secrets.SSH_EC2_HOSTNAME }}
          USER: ${{ secrets.SSH_EC2_USER }}
          YEAR: ${{ secrets.YEAR }}
          DB_TYPE: ${{ secrets.DB_TYPE }}
          TURSO_DATABASE_URL: ${{ secrets.TURSO_DATABASE_URL }}
          TURSO_AUTH_TOKEN: ${{ secrets.TURSO_AUTH_TOKEN }}
        run: |
          echo "$KEY" > private_key && chmod 600 private_key
          ssh -v -o StrictHostKeyChecking=no -i private_key ${USER}@${HOSTNAME} '
            cd ~/courses-api
            aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/courses-api/courses-api.tar.gz .
            aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/courses-api/docker-compose.yml .
            echo YEAR=${{ secrets.YEAR }} > .env
            echo DB_TYPE=${{ secrets.DB_TYPE }} >> .env
            echo TURSO_DATABASE_URL=${{ secrets.TURSO_DATABASE_URL }} >> .env
            echo TURSO_AUTH_TOKEN=${{ secrets.TURSO_AUTH_TOKEN }} >> .env
            docker load -i courses-api.tar.gz
            docker compose up -d
          '
